{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7bqOG46DDz",
        "colab_type": "text"
      },
      "source": [
        "# **CNN to find LRF from point clouds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdsKQZkNNyGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/your_project_folder/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z3uNLF7RqxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiHWv0Tebbtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# import scipy.io\n",
        "# import pandas as pd\n",
        "\n",
        "# path = \"content/drive/My Drive/data/04461d008.mat\"\n",
        "# mat = scipy.io.loadmat(path)['Ftr']\n",
        "\n",
        "# path1 = \"content/drive/My Drive/data/04724d006.mat\"\n",
        "# mat1 = scipy.io.loadmat(path1)['Ftr']\n",
        "# # Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChq6kI3NcmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('04461d008.mat')['Ftr']\n",
        "L1=list(mat)\n",
        "\n",
        "Z1=[]\n",
        "P1=[]\n",
        "\n",
        "# Z=np.asarray(L1[0][0][i][0][k])\n",
        "\n",
        "\n",
        "# print(Z)\n",
        "\n",
        "# LRFs\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L1[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L1[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "# print(P1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJRAUVj2MGXw",
        "colab_type": "code",
        "outputId": "2dfcbbf6-941e-41e7-9a7e-62c8ab730326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "mat1 = scipy.io.loadmat(\"04724d006.mat\")['Ftr']\n",
        "L2=list(mat1)\n",
        "\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L2[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L2[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "# print(P1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mat3 = scipy.io.loadmat(\"04727d003.mat\")['Ftr']\n",
        "L4=list(mat3)\n",
        "\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L4[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L4[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "mat4 = scipy.io.loadmat(\"04849d001.mat\")['Ftr']\n",
        "L5=list(mat4)\n",
        "\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L5[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L5[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "\n",
        "   \n",
        "mat5 = scipy.io.loadmat(\"04871d003.mat\")['Ftr']\n",
        "L6=list(mat5)\n",
        "\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L6[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L6[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "   \n",
        "mat6 = scipy.io.loadmat(\"05097d002.mat\")['Ftr']\n",
        "L7=list(mat6)\n",
        "\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L7[0][0][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  Z1.append(K)\n",
        "# print(Z1)\n",
        "\n",
        "# Neighbours\n",
        "for i in range(0,500):\n",
        "  Z=np.asarray(L7[0][1][i][0])\n",
        "  K=np.ndarray.tolist(Z)\n",
        "  P1.append(K)\n",
        "  \n",
        "  \n",
        "\n",
        "Z2=np.asarray(Z1)\n",
        "P2=np.asarray(P1)\n",
        "\n",
        "print(len(Z2))\n",
        "\n",
        "print(len(P2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjWXad53Q53c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(P2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kBZTbnJqKZE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4McMMhhzQoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(P2,Z2,test_size=0.25,random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg63u6hE3m0C",
        "colab_type": "code",
        "outputId": "89167aa9-9093-469f-a861-d99e2f43589f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model \n",
        "from keras.layers import Conv1D, Flatten, Dense ,MaxPooling1D, Dropout , BatchNormalization \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bd0V3gr8wSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_mod():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv1D(64, \n",
        "                   kernel_size=11,strides=4, \n",
        "                   activation=\"relu\",             \n",
        "                   input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "  \n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling1D(pool_size=(2)))\n",
        "  \n",
        "  model.add(Conv1D(64, \n",
        "                   kernel_size=5,strides=2, \n",
        "                   activation=\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(MaxPooling1D(pool_size=(2)))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(Conv1D(64, \n",
        "                   kernel_size=5,strides=2, \n",
        "                   activation=\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  model.add(Conv1D(64, \n",
        "                   kernel_size=3, \n",
        "                   activation=\"relu\"))\n",
        " \n",
        " \n",
        " \n",
        "  \n",
        "  model.add(Conv1D(64, \n",
        "                   kernel_size=3, \n",
        "                   activation=\"relu\"))\n",
        "  model.add(MaxPooling1D(pool_size=(2)))\n",
        "  \n",
        "  #model.add(BatchNormalization())\n",
        "  \n",
        "#   model.add(Conv1D(16, \n",
        "#                    kernel_size=5, \n",
        "#                    activation=\"relu\"))\n",
        "\n",
        "\n",
        "  model.add(Dropout(0.38))\n",
        "  \n",
        " \n",
        "  model.add(Dense((64), activation=\"relu\"))\n",
        "  model.add(Dense((32), activation=\"relu\"))\n",
        "  model.add(Dense((3), activation=\"linear\"))\n",
        "  \n",
        "\n",
        "#   model.add(Dropout(0.2))\n",
        "#opt = optimizers.Adam(lr=LR)\n",
        "\n",
        "  model.summary()\n",
        " \n",
        "\n",
        "  return model\n",
        "  # model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "# trainer = model.evaluate(x_train, y_train, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])\n",
        "# print('Train loss:',trainerr[0])\n",
        "# print('Train accuracy:',trainerr[1])\n",
        "\n",
        "\n",
        "model_history1=[]\n",
        "n_folds=1\n",
        "epochs=100\n",
        "batch_size=5\n",
        "\n",
        "\n",
        "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS, BATCH_SIZE):\n",
        "    \n",
        "    model= cnn_mod()\n",
        "    history = model.fit(t_x, t_y, epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
        "              verbose=1, validation_split=0.1)  \n",
        "    \n",
        "    print(\"Training Score: \", model.evaluate(t_x, t_y))\n",
        "    print(\"Validation Score: \", model.evaluate(val_x, val_y))\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    return history\n",
        "\n",
        "\n",
        "for i in range(n_folds):\n",
        "    print(\"Training on Fold: \",i+1)\n",
        "    t_x, val_x, t_y, val_y = train_test_split(x_train, y_train, test_size=0.25, \n",
        "                                               random_state = np.random.randint(1,100, 1)[0])\n",
        "    model_history1.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n",
        "    print(\"=======\"*12, end=\"\\n\\n\\n\")\n",
        "    \n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI_d_HGmLKwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htUHjtXgFx6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_predict = np.random.rand(1, 1499, 3)\n",
        "\n",
        "print(x_predict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgvEXNQOCs4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.predict(x_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na40cUvlRtud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "G=(model.predict(P5))\n",
        "#print(G)\n",
        "p0= G[0][0]\n",
        "p1= G[0][1]\n",
        "p2= G[0][2]\n",
        "print(p0)\n",
        "x,y,z= P5.T\n",
        "U,V,W= zip(p0,p1,p2)\n",
        "X,Y,Z= zip(-p0,-p1,-p2)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(x,y,z)\n",
        "ax.quiver(X,Y,Z,U,V,W,arrow_length_ratio=0.01)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}