{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wroBkJoc2YfP",
        "colab_type": "code",
        "outputId": "2d829cf2-349d-4398-8944-4cae26be3dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "root_path = 'gdrive/My Drive/data1/'\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "Z1=[]\n",
        "P1=[]\n",
        "\n",
        "for q in range(100,110):\n",
        "  filname = root_path + str(q) + \".mat\"\n",
        "  \n",
        "  mat = scipy.io.loadmat(filname)['Ftr']\n",
        "  L1=list(mat)\n",
        "\n",
        "  # LRFs\n",
        "  for i in range(0,500):\n",
        "    Z=[]\n",
        "    for j in range(0,2):\n",
        "      Z.append(L1[0][0][i][0][j])\n",
        "    K=np.ndarray.tolist(np.asarray(Z))\n",
        "    Z1.append(K)\n",
        "  # print(Z1)\n",
        "\n",
        "  # Neighbours\n",
        "  for i in range(0,500):\n",
        "    \n",
        "    K=np.ndarray.tolist(np.asarray(L1[0][1][i][0]))\n",
        "    P1.append(K)\n",
        "  # print(P1)\n",
        "\n",
        "\n",
        "Z1=np.asarray(Z1)\n",
        "P1=np.asarray(P1)\n",
        "\n",
        "print((Z1.shape))\n",
        "print((P1.shape))\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(P1,Z1,test_size=0.25,random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "(5000, 2, 3)\n",
            "(5000, 1499, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvhfxdDl3pT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM and CNN for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "\n",
        "embedding_vecor_length = 1499\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}